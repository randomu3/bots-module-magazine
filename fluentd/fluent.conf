# Fluentd configuration for comprehensive log aggregation

<system>
  log_level info
  suppress_repeated_stacktrace true
  emit_error_log_interval 30s
  suppress_config_dump
</system>

# Backend application logs
<source>
  @type tail
  path /var/log/backend/*.log
  pos_file /var/log/fluentd/backend.log.pos
  tag backend.app
  <parse>
    @type json
    time_key timestamp
    time_format %Y-%m-%dT%H:%M:%S.%L%z
  </parse>
  refresh_interval 5s
  read_from_head true
</source>

# Frontend application logs (if available)
<source>
  @type tail
  path /var/log/frontend/*.log
  pos_file /var/log/fluentd/frontend.log.pos
  tag frontend.app
  <parse>
    @type json
    time_key timestamp
    time_format %Y-%m-%dT%H:%M:%S.%L%z
  </parse>
  refresh_interval 5s
  read_from_head true
</source>

# Nginx access logs
<source>
  @type tail
  path /var/log/nginx/access.log
  pos_file /var/log/fluentd/nginx-access.log.pos
  tag nginx.access
  <parse>
    @type nginx
  </parse>
  refresh_interval 5s
</source>

# Nginx error logs
<source>
  @type tail
  path /var/log/nginx/error.log
  pos_file /var/log/fluentd/nginx-error.log.pos
  tag nginx.error
  <parse>
    @type regexp
    expression /^(?<time>\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2}) \[(?<log_level>\w+)\] (?<pid>\d+).(?<tid>\d+): (?<message>.*)$/
    time_format %Y/%m/%d %H:%M:%S
  </parse>
  refresh_interval 5s
</source>

# PostgreSQL logs
<source>
  @type tail
  path /var/log/postgresql/*.log
  pos_file /var/log/fluentd/postgresql.log.pos
  tag postgresql.app
  <parse>
    @type regexp
    expression /^(?<time>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}.\d{3} \w+) \[(?<pid>\d+)\] (?<log_level>\w+): (?<message>.*)$/
    time_format %Y-%m-%d %H:%M:%S.%L %Z
  </parse>
  refresh_interval 10s
</source>

# Redis logs
<source>
  @type tail
  path /var/log/redis/*.log
  pos_file /var/log/fluentd/redis.log.pos
  tag redis.app
  <parse>
    @type regexp
    expression /^(?<pid>\d+):(?<role>\w+) (?<time>\d{2} \w{3} \d{4} \d{2}:\d{2}:\d{2}.\d{3}) (?<log_level>.) (?<message>.*)$/
    time_format %d %b %Y %H:%M:%S.%L
  </parse>
  refresh_interval 10s
</source>

# Docker container logs
<source>
  @type tail
  path /var/lib/docker/containers/*/*-json.log
  pos_file /var/log/fluentd/docker.log.pos
  tag docker.*
  <parse>
    @type json
    time_key time
    time_format %Y-%m-%dT%H:%M:%S.%L%z
  </parse>
  refresh_interval 10s
</source>

# System logs
<source>
  @type systemd
  tag systemd
  path /var/log/journal
  <storage>
    @type local
    persistent true
    path /var/log/fluentd/systemd.pos
  </storage>
  <entry>
    field_map {"MESSAGE": "message", "_HOSTNAME": "hostname", "_SYSTEMD_UNIT": "unit"}
    fields_strip_underscores true
    fields_lowercase true
  </entry>
</source>

# Filter to add common fields
<filter **>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    service_name "${tag_parts[0]}"
    environment "${ENV['NODE_ENV'] || 'production'}"
    cluster "${ENV['CLUSTER_NAME'] || 'default'}"
    version "${ENV['APP_VERSION'] || '1.0.0'}"
  </record>
</filter>

# Parse and enrich backend application logs
<filter backend.app>
  @type record_transformer
  <record>
    severity ${record["level"] || "info"}
    component "backend"
  </record>
</filter>

# Parse and enrich frontend application logs
<filter frontend.app>
  @type record_transformer
  <record>
    severity ${record["level"] || "info"}
    component "frontend"
  </record>
</filter>

# Enrich nginx logs
<filter nginx.**>
  @type record_transformer
  <record>
    component "nginx"
    severity ${tag_parts[1] == "error" ? "error" : "info"}
  </record>
</filter>

# Enrich database logs
<filter postgresql.app>
  @type record_transformer
  <record>
    component "postgresql"
    severity ${record["log_level"] ? record["log_level"].downcase : "info"}
  </record>
</filter>

# Enrich Redis logs
<filter redis.app>
  @type record_transformer
  <record>
    component "redis"
    severity ${record["log_level"] == "." ? "info" : record["log_level"] == "#" ? "warn" : "error"}
  </record>
</filter>

# Parse Docker container logs
<filter docker.**>
  @type record_transformer
  <record>
    component "docker"
    container_name "${tag_parts[1]}"
    severity "info"
  </record>
</filter>

# Security event detection
<filter **>
  @type grep
  <regexp>
    key message
    pattern /(authentication failed|unauthorized access|security violation|brute force|sql injection|xss attempt)/i
  </regexp>
  tag security.${tag}
</filter>

# Error detection and classification
<filter **>
  @type grep
  <regexp>
    key severity
    pattern ^(error|fatal|critical|emergency)$
  </regexp>
  tag error.${tag}
</filter>

# Performance issue detection
<filter **>
  @type grep
  <regexp>
    key message
    pattern /(slow query|timeout|high memory|high cpu|performance degradation)/i
  </regexp>
  tag performance.${tag}
</filter>

# Business event detection
<filter **>
  @type grep
  <regexp>
    key message
    pattern /(user registration|payment|module activation|bot connection)/i
  </regexp>
  tag business.${tag}
</filter>

# Rate limiting for high-volume logs
<filter nginx.access>
  @type sampling
  interval 10
  sample_unit tag
</filter>

# Output configurations

# Console output for development
<match **>
  @type copy
  <store>
    @type stdout
    <format>
      @type json
    </format>
  </store>
  
  # File output for local storage
  <store>
    @type file
    path /var/log/fluentd/aggregated
    <format>
      @type json
    </format>
    <buffer>
      @type file
      path /var/log/fluentd/buffer/
      flush_mode interval
      flush_interval 30s
      chunk_limit_size 64m
      queue_limit_length 128
      retry_max_interval 30
      retry_forever true
    </buffer>
  </store>
</match>

# Security alerts to Slack
<match security.**>
  @type slack
  webhook_url "${ENV['SECURITY_SLACK_WEBHOOK']}"
  channel "#security-alerts"
  username "Security Monitor"
  icon_emoji ":warning:"
  title "Security Alert: %s"
  title_keys message
  message "Security event detected: %s\nHost: %s\nService: %s\nTime: %s"
  message_keys message,hostname,service_name,timestamp
  color danger
  flush_interval 1s
</match>

# Critical errors to Slack
<match error.**>
  @type slack
  webhook_url "${ENV['ERROR_SLACK_WEBHOOK']}"
  channel "#critical-errors"
  username "Error Monitor"
  icon_emoji ":exclamation:"
  title "Critical Error: %s"
  title_keys message
  message "Error detected: %s\nHost: %s\nService: %s\nSeverity: %s\nTime: %s"
  message_keys message,hostname,service_name,severity,timestamp
  color danger
  flush_interval 5s
</match>

# Performance issues to monitoring channel
<match performance.**>
  @type slack
  webhook_url "${ENV['PERFORMANCE_SLACK_WEBHOOK']}"
  channel "#performance-alerts"
  username "Performance Monitor"
  icon_emoji ":chart_with_downwards_trend:"
  title "Performance Issue: %s"
  title_keys message
  message "Performance issue detected: %s\nHost: %s\nService: %s\nTime: %s"
  message_keys message,hostname,service_name,timestamp
  color warning
  flush_interval 10s
</match>

# Business events to analytics
<match business.**>
  @type http
  endpoint "${ENV['ANALYTICS_WEBHOOK_URL']}"
  http_method post
  <format>
    @type json
  </format>
  <buffer>
    flush_interval 60s
    chunk_limit_size 1m
  </buffer>
</match>

# Elasticsearch output for log storage and search
# <match **>
#   @type elasticsearch
#   host "${ENV['ELASTICSEARCH_HOST'] || 'elasticsearch'}"
#   port "${ENV['ELASTICSEARCH_PORT'] || 9200}"
#   user "${ENV['ELASTICSEARCH_USER']}"
#   password "${ENV['ELASTICSEARCH_PASSWORD']}"
#   index_name "telegram-bot-platform-%Y.%m.%d"
#   type_name "_doc"
#   include_tag_key true
#   tag_key @log_name
#   <buffer>
#     @type file
#     path /var/log/fluentd/elasticsearch
#     flush_mode interval
#     flush_interval 30s
#     chunk_limit_size 32m
#     queue_limit_length 64
#     retry_max_interval 30
#     retry_forever true
#   </buffer>
# </match>

# Prometheus metrics output
# <match **>
#   @type prometheus
#   <metric>
#     name fluentd_input_status_num_records_total
#     type counter
#     desc The total number of incoming records
#     <labels>
#       tag ${tag}
#       hostname ${hostname}
#     </labels>
#   </metric>
# </match>